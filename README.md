# CAD-dataset
Over a six-month period, data collection for the CAD study was meticulously conducted across multiple medical centers. A unified data collection protocol was established to ensure consistency in diagnostic measurements and recording practices, using standardized equipment and diagnostic methods across participating facilities. Medical centers ranging from large hospitals to specialized heart clinics contributed to a comprehensive dataset, operating under strict ethical guidelines with all centters' approvals and patient consent.

Clear inclusion criteria were defined, selecting patients based on age, cardiac history, and risk factors to ensure a representative sample. Data capture schedules were set bi-weekly, allowing for the collection of real-time updates on patient health status. Electronic health record (EHR) systems were integrated with custom data extraction scripts to automate data retrieval efficiently, ensuring a seamless and timely collection process.

Throughout the study, vital attributes were recorded for the classification of CAD types. For Obstructive CAD, data included the degree of arterial narrowing, plaque extent, blood flow measurements, and lipid profiles. For Non-Obstructive CAD, features such as imaging data, stress test results, and endothelial markers were noted. For Spontaneous Coronary Artery Dissection (SCAD), records included findings of arterial wall dissection, imaging results of intramural hematomas, and relevant patient history such as pregnancy status and the presence of connective tissue disorders.

Quality control measures were put in place to maintain data accuracy, including periodic data verification checks and audits by a dedicated team. Automated scripts flagged potential anomalies for further investigation to ensure the integrity of the collected data. Patient privacy was safeguarded through comprehensive anonymization protocols, with personal identifiers removed and pseudonymization applied. All data transfers between medical centers and the centralized repository were securely managed.

Data integration from all centers was performed to compile a standardized dataset, with preprocessing steps such as imputation for missing values and normalization applied to align feature distributions. Each data point was tagged with metadata indicating the time and source of collection, enabling traceability for future validation studies. Periodic review meetings were held with the data collection team, ensuring any issues were promptly addressed and feedback from participating centers was incorporated to refine the process.
